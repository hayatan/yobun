---
description: 
globs: 
alwaysApply: true
---

# Yobun リポジトリ コーディングルール

このプロジェクトのコーディングルールを記載します。
コードの変更時はこのドキュメント含め、各AGENTS.md や README.md などのドキュメントと常に整合性を保つようにドキュメントも常に保守してください。

## 1. プロジェクト構造
### 1.1 ディレクトリ構造
- `src/`: ソースコードのルートディレクトリ
  - `api/`: APIルーティングと状態管理
    - `routes/`: エンドポイント別ルーター
    - `state-manager.js`: ジョブ状態管理
  - `config/`: 設定ファイル
    - `constants.js`: 定数定義
    - `sources/`: データソース別設定
    - `slorepo-config.js`: 店舗設定
    - `heatmap-layouts/`: ヒートマップレイアウト設定
  - `db/`: データベース関連の処理
    - `sqlite/`: SQLite関連（プライマリストレージ）
    - `bigquery/`: BigQuery関連（分析用DB）
  - `services/`: ビジネスロジック
    - `slorepo/`: スクレイピング処理
    - `datamart/`: データマート更新
  - `scheduler/`: スケジューラー
  - `util/`: 共通ユーティリティ関数
- `sql/`: SQLスキーマとマイグレーション
  - `raw_data/`: 生データスキーマ管理
  - `scrape_failures/`: 失敗記録スキーマ
  - `manual_corrections/`: 手動補正スキーマ
  - `datamart/`: データマートSQL
- `public/`: 静的ファイル（HTML）

### 1.2 ファイル命名規則
- スネークケース (`snake_case`) またはケバブケース (`kebab-case`) を使用
- 例: `slorepo-config.js`, `state-manager.js`

## 2. コーディング規約

### 2.1 モジュール
- ES6モジュールを使用
  ```javascript
  import module from './module.js';
  export default function() { ... }
  ```
- ファイル拡張子`.js`を明示的に指定

### 2.2 非同期処理
- `async/await`を基本とする
  ```javascript
  const process = async () => {
    try {
      await someAsyncOperation();
    } catch (error) {
      console.error('エラーの詳細:', error);
    }
  };
  ```
- エラーハンドリングは`try/catch`で統一

### 2.3 データ処理
- 数値データの整形は`util/common.js`に集約
  ```javascript
  const cleanNumber = (value) => {
    return parseInt(value.replace(/,/g, '').replace(/^\+/, ''));
  };
  ```

### 2.4 ログ出力
- 日付とホール名を明示的に表示
  ```javascript
  console.log(`[${date}][${hole.name}] 機種 ${index + 1}/${machines.length}: ${machine.name} を処理中...`);
  ```
- エラーメッセージは具体的に記述
  ```javascript
  console.error(`[${date}][${hole.name}] 機種: ${machineName} の取得に失敗しました。 status=${status}`);
  ```

### 2.5 設定管理
- 環境変数は`dotenv`で管理
- 定数は`src/config/constants.js`に集約
- ホール設定は`slorepo-config.js`に集約
  ```javascript
  export default {
    holes: [
      {
        name: "店舗名",
        code: "店舗コード",
        priority: "high",      // high, normal, low
        region: "秋葉原",
        active: true,
        lateUpdate: false
      }
    ],
    getHoles: function(filter = {}) { ... }
  };
  ```

### 2.6 データベース操作
- SQLiteをプライマリストレージとして使用（Litestreamでバックアップ）
- BigQueryは分析用DBとして同期
- **BigQuery同期方式**: GCS経由のLoad Job使用
  ```javascript
  // src/db/bigquery/operations.js
  // 1. データをNDJSON形式でGCSに一時アップロード
  // 2. Load JobでBigQueryにロード
  // 3. 一時ファイルを削除
  
  // 単一店舗: DELETE後にLoad Job (WRITE_APPEND)
  // 複数店舗: Load Job (WRITE_TRUNCATE)
  ```
- スキーマは`sql/raw_data/schema.js`で一元管理
  ```javascript
  import { RAW_DATA_SCHEMA } from '../../../sql/raw_data/schema.js';
  
  const schema = RAW_DATA_SCHEMA.toBigQuerySchema();
  const createTable = RAW_DATA_SCHEMA.toSQLiteCreateTable();
  const id = RAW_DATA_SCHEMA.generateId(date, hole, machineNumber, source);
  ```

### 2.7 スクレイピング処理
- Puppeteer + Stealth プラグイン使用
  ```javascript
  import puppeteer from 'puppeteer-extra';
  import StealthPlugin from 'puppeteer-extra-plugin-stealth';
  puppeteer.use(StealthPlugin());
  ```
- **リトライ機能**: 429/5xxエラー時、指数バックオフで最大3回
- **エラー分類**: `cloudflare`, `timeout`, `network`, `parse`, `http_error`, `unknown`
- **失敗記録**: エラー発生時は `scrape_failures` テーブルに自動記録
- エラーハンドリング（continueOnError オプション）
  ```javascript
  const results = await scrape(bigquery, datasetId, tableIdPrefix, db, start, end, updateProgress, {
    continueOnError: true,
    force: false,
    priorityFilter: 'high'  // high, normal, low, all
  });
  ```

### 2.8 失敗管理・手動補正
- **失敗記録**: スクレイピング失敗を `scrape_failures` に自動記録
- **手動補正**: 管理画面でクリップボード貼り付け → `manual_corrections` に保存
- **フォールバック**: 再取得失敗時、`manual_corrections` から自動復元
- DB操作:
  - `src/db/sqlite/failures.js` - 失敗記録CRUD
  - `src/db/sqlite/corrections.js` - 手動補正CRUD

### 2.9 ユーティリティ関数
- 共通処理は`util`ディレクトリに集約
- 関数の責務を明確に分離

## 3. データ処理

### 3.1 データ整形
- 数値データは適切に整形してから使用
  ```javascript
  function cleanNumber(value) {
    return parseInt(value.replace(/,/g, '').replace(/^\+/, ''));
  }
  ```

### 3.2 データ構造
- オブジェクトは明確なプロパティ名を使用
- 配列操作は map, filter, reduce などの関数型メソッドを優先
- データには必ず`source`フィールドを含める

## 4. 外部ライブラリ

### 4.1 Puppeteer
- ページ遷移時は適切なインターバルを設定（`SCRAPING.intervalMs`）
- セレクタは設定ファイルで管理
- エラーハンドリングを必ず実装

## 5. 設定ファイル

### 5.1 構成
- 環境依存の値は設定ファイルに分離
- 定数は`src/config/constants.js`
- データソース設定は`src/config/sources/`
- 店舗設定は`src/config/slorepo-config.js`

## 6. ログ出力

### 6.1 ログレベル
- エラー: `console.error()`
- 情報: `console.log()`
- デバッグ情報は本番環境では出力しない

### 6.2 ログフォーマット
- 日時、処理内容、対象を明確に記載
  ```javascript
  console.log(`[${date}][${hole.name}] 機種 ${index + 1}/${machines.length}: ${machine.name} を処理中...`);
  ```

## 7. インフラストラクチャ

### 7.1 実行環境
- **Dockerのみ**を使用（ローカル直接実行は非推奨）
  ```bash
  make build
  make run-docker
  ```
- クラウド実行: Google Cloud Run

### 7.2 APIエンドポイント
- ルーティングは`src/api/routes/`で管理
- 状態管理は`src/api/state-manager.js`で集中管理
  ```javascript
  import { jobStateManager } from '../state-manager.js';
  
  jobStateManager.startJob('scrape');
  jobStateManager.updateProgress('scrape', current, total, message);
  jobStateManager.completeJob('scrape');
  ```
- 主要エンドポイント（詳細は`README.md`参照）:
  - **スクレイピング**: `POST /pubsub`, `GET /status`
  - **同期**: `POST /util/sync`, `GET /util/sync/status`
  - **再取得**: `POST /util/force-rescrape`, `GET /util/force-rescrape/status`
  - **データ状態**: `GET /api/data-status`, `DELETE /api/data-status/raw`
  - **失敗管理**: `GET/PATCH/DELETE /api/failures`, `GET /api/failures/stats`
  - **手動補正**: `POST/GET/DELETE /api/corrections`, `POST /api/corrections/parse`
  - **重複削除**: `GET/POST /util/dedupe/*`
  - **スケジュール**: `GET/PUT/POST/DELETE /api/schedules/*`
  - **データマート**: `GET/DELETE/POST /api/datamart/*`
  - **イベント管理**: `GET/POST/PATCH/DELETE /api/events/*`
  - **イベントタイプ**: `GET/POST/PATCH/DELETE /api/event-types/*`
  - **ヒートマップ**: `GET/PUT /api/heatmap/*`（エディタは `?perf=true` でパフォーマンス計測モード有効）
  - **ヘルスチェック**: `GET /health`

### 7.3 データベース管理
- SQLiteデータベースの永続化（Litestream → GCS）
- スキーマは`sql/raw_data/schema.js`で一元管理
- マイグレーションは`sql/*/migrations/`に配置

### 7.4 コンテナ化
- 軽量なNode.jsイメージを使用
  ```dockerfile
  FROM node:23-slim
  RUN apt-get update && apt-get install -y sqlite3 curl
  ```

### 7.5 環境変数
- 主要な環境変数:
  - `NODE_ENV`: 実行環境
  - `SQLITE_DB_PATH`: SQLiteデータベースパス
  - `GOOGLE_CLOUD_PROJECT`: GCPプロジェクトID
  - `GOOGLE_APPLICATION_CREDENTIALS`: 認証情報パス
  - `ENABLE_SCHEDULER`: スケジューラーの有効化

### 7.6 エラーハンドリング
- `continueOnError`オプションで処理継続可能
- `results.success`, `results.failed`, `results.skipped` で結果確認

## 8. スキーマ管理

### 8.1 Single Source of Truth
- スキーマは`sql/raw_data/schema.js`で一元管理
- SQLiteとBigQuery両方のスキーマを生成
  ```javascript
  export const RAW_DATA_SCHEMA = {
    version: '2.0.0',
    columns: [...],
    toBigQuerySchema() { ... },
    toSQLiteCreateTable(tableName) { ... },
    generateId(date, hole, machineNumber, source) { ... }
  };
  ```

### 8.2 マイグレーション
- マイグレーションファイルは`sql/*/migrations/`に配置
- SQLiteとBigQuery用に分けて管理
  - `001_add_source_column.sqlite.sql`
  - `001_add_source_column.bq.sql`

## 9. Serena MCP使用ガイドライン

- **複雑なコード解析**や**アーキテクチャ理解**が必要な場面では積極的にSerenaを使用する

### 9.1 Serena推奨場面
- コードベース全体の構造理解
- シンボル間の参照関係調査
- クラス・関数・変数の使用箇所特定
- ファイル間の依存関係分析
- 大規模リファクタリングの影響範囲調査
- 設計パターンの実装箇所探索
- バグの原因となる関連コード特定

### 9.2 通常ツール推奨場面
- 単純なファイル読み込み・編集
- 既知のファイル・関数への直接的な変更
- シンプルな文字列検索・置換

### 9.3 使用方針
- Serena MCPの機能を活用して効率的で正確なコード分析を心がける
